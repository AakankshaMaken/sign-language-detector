# ğŸ¤Ÿ Sign Language Detection using Deep Learning and OpenCV

A real-time sign language recognition system using MediaPipe for hand tracking, LSTM neural networks for temporal sequence classification, and OpenCV for video stream handling.

---

## ğŸ“¹ Demo
https://drive.google.com/file/d/19iaxnNY1D5eIaSQV-lnUYkN90lugIfE2/view?usp=drive_link 


---

## ğŸ§  Model Overview

- **Input**: Live webcam feed with hand gestures
- **Preprocessing**: Hand landmark extraction using MediaPipe
- **Model**: LSTM Neural Network
- **Output**: Predicted letter or digit (A-Z, 1-9)

---

## ğŸ› ï¸ Tech Stack

- Python 3.8+
- OpenCV
- MediaPipe
- TensorFlow / Keras
- NumPy
- Scikit-learn

---

## ğŸ“ Project Structure

```
sign-language-detector/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.py               # Real-time sign language detection
â”‚   â”œâ”€â”€ collectdata.py       # Collects raw hand gesture images
â”‚   â”œâ”€â”€ data.py              # Extracts MediaPipe keypoints to .npy files
â”‚   â”œâ”€â”€ trainmodel.py        # LSTM model training script
â”‚   â””â”€â”€ function.py          # Utility functions (MediaPipe, landmarks, etc.)
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ model.h5             # Trained model weights
â”‚   â””â”€â”€ model.json           # Model architecture
â”œâ”€â”€ demo/
â”‚   â””â”€â”€ demo.gif             # Demo of the working app
```



